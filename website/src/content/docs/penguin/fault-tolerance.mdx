---
title: Fault Tolerance
description: How Blizzard and Penguin provide crash recovery and exactly-once semantics
---

import PollingCaveat from '../../../components/PollingCaveat.astro';

The Blizzard/Penguin pipeline provides fault tolerance through a watermark-based coordination protocol. This two-stage architecture ensures data is never lost or duplicated, even when either component crashes.

## Architecture Overview

```d2
direction: right
Fault Tolerance Flow: {
  blizzard: Blizzard {
    label: "Blizzard\n(Parquet)"
  }
  table_dir: Table Directory {
    label: "Table Directory\n(Parquet)"
  }
  penguin: Penguin {
    label: "Penguin\n(Commits)"
  }

  blizzard -> table_dir -> penguin

  parquet_files: "{partition}/*.parquet"
  delta_log: "_delta_log/\n*.json"

  table_dir -> parquet_files
  penguin -> delta_log
}
```

## Coordination Protocol

<PollingCaveat />

### 1. Blizzard Writes Files

When Blizzard finishes processing a source file:

1. Writes Parquet file to `{table_uri}/{partition}/{uuidv7}.parquet`

File names use UUIDv7 which provides lexicographic ordering by time, enabling efficient watermark-based discovery.

### 2. Penguin Commits to Delta Lake

Penguin scans the table directory and for each uncommitted file:

1. Scans for files above the current watermark
2. Reads parquet metadata (schema, record count)
3. Commits the Parquet file to Delta Lake
4. Updates watermark to highest committed path

The watermark is stored in the Delta log via Txn actions for crash recovery.

## Failure Scenarios

### Blizzard Crashes During Write

```
State: Partial parquet file written
Result: File may be corrupted/incomplete
Recovery: Penguin skips unreadable files, Blizzard reprocesses source
```

Penguin validates parquet files during schema inference and skips corrupted files.

### Blizzard Crashes After Write

```
State: Complete parquet file in table directory
Result: Penguin will discover and commit the file
Recovery: Automatic - Penguin finds files above watermark
```

### Penguin Crashes Before Commit

```
State: Files exist but not in Delta log
Result: Files not yet committed
Recovery: Automatic - Penguin rescans from watermark on restart
```

### Penguin Crashes After Commit, Before Watermark Update

```
State: File committed, watermark not updated
Result: Penguin may attempt to re-commit
Recovery: Delta Lake's optimistic concurrency handles duplicates
```

Delta Lake's transactional guarantees ensure that duplicate commits are rejected.

## Guarantees

| Guarantee | How It's Achieved |
|-----------|-------------------|
| **No data loss** | Files persist in table directory until committed |
| **No duplicates** | Delta Lake rejects duplicate file additions |
| **Crash resilience** | Both components can restart and resume |
| **Independent scaling** | Blizzard and Penguin operate independently |

## Directory Structure

```
table_uri/
├── _delta_log/                    # Delta transaction log
│   ├── 00000000000000000000.json
│   ├── 00000000000000000001.json
│   └── ...
├── date=2024-01-01/               # Partitioned parquet files
│   ├── 019234ab-cdef-7890.parquet
│   └── 019234ab-cdef-7891.parquet
└── date=2024-01-02/
    └── 019234ab-cdef-7892.parquet
```

## Comparison to Single-Process Architecture

The two-stage architecture has several advantages over a single process that does both ingestion and commits:

| Aspect | Single Process | Two-Stage (Blizzard + Penguin) |
|--------|----------------|--------------------------------|
| **Failure isolation** | Crash loses in-flight data | Components fail independently |
| **Backpressure** | Commit latency affects ingestion | Ingestion continues while commits catch up |
| **Scaling** | Single bottleneck | Scale writers and committers independently |
| **Recovery** | Must checkpoint all state atomically | Watermark in Delta log is the checkpoint |

## Operational Considerations

### Monitoring Uncommitted Files

Monitor the number of uncommitted files using the `penguin_pending_files` metric.

A growing count indicates Penguin is falling behind.

### Cleaning Orphaned Files

If Blizzard crashes repeatedly, orphaned Parquet files may accumulate. These can be identified as files without corresponding metadata and removed manually.

### Penguin Polling Interval

Configure Penguin's poll interval based on latency requirements:

```yaml
tables:
  events:
    table_uri: "s3://bucket/events"
    poll_interval_secs: 10  # Check for new files every 10 seconds
```

Lower intervals reduce commit latency but increase API calls.